{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CQF Exam One"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Portfolio Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define $\\Sigma$ and vector 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define S\n",
    "S = np.array([  [0.07, 0, 0, 0],\n",
    "                [0, 0.28, 0, 0],\n",
    "                [0, 0, 0.25, 0],\n",
    "                [0, 0, 0, 0.31]])\n",
    "\n",
    "# Define R\n",
    "R = np.array([  [1, 0.4, 0.3, 0.3],\n",
    "                [0.4, 1, 0.27, 0.42],\n",
    "                [0.3, 0.27, 1, 0.5],\n",
    "                [0.3, 0.42, 0.5, 1]])\n",
    "\n",
    "\n",
    "# Compute the matrix multiplication\n",
    "Sigma = np.dot(np.dot(S, R), S)\n",
    "\n",
    "# Calculate the inverse of Sigma\n",
    "Sigma_inv = np.linalg.inv(Sigma)\n",
    "\n",
    "# Define the vector 1\n",
    "vector_1 = np.ones((4, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if $\\Sigma$ is positive definite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, _ = np.linalg.eig(Sigma)\n",
    "print([eigenvalue.round(4) for eigenvalue in eigenvalues])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary multiplications\n",
    "result = np.dot(np.dot(Sigma_inv, vector_1).T, vector_1)\n",
    "\n",
    "# Calculate lambda\n",
    "lambda_value = 1 / result[0, 0]\n",
    "\n",
    "print(\"Lambda =\", lambda_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve for $w^*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_star =  np.dot(lambda_value, np.dot(Sigma_inv,vector_1))\n",
    "print(w_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mean return vector mu\n",
    "mu = np.array([[0.05], [0.07], [0.15], [0.22]])\n",
    "# Define constrain m = 7%\n",
    "m = 0.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the new correlation matrix $\\Sigma_{1}$, $\\Sigma_{2}$ and $\\Sigma_{3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling factors\n",
    "scaling_factors = [1, 1.3, 1.8]\n",
    "\n",
    "# Apply scaling and constraints using map() function\n",
    "new_corr_matrices = list(map(lambda factor: np.clip(R * factor, None, 0.99), scaling_factors))\n",
    "\n",
    "# Set diagonal elements back to 1 for each new correlation matrix\n",
    "for matrix in new_corr_matrices:\n",
    "    np.fill_diagonal(matrix, 1)\n",
    "\n",
    "# Compute new sigma\n",
    "\n",
    "Sigma_1 = Sigma\n",
    "Sigma_2 = np.dot(np.dot(S, new_corr_matrices[1]), S)\n",
    "Sigma_3 = np.dot(np.dot(S, new_corr_matrices[2]), S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a optimization function to compute vector $w^*$ given the input $m=7\\%$, correlation matrix $\\Sigma$ and mean return $\\mu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(Sigma, mu, m):\n",
    "    vector_1 = np.ones((4, 1))\n",
    "    \n",
    "    # Compute A, B, and C\n",
    "    A = np.dot(np.dot(vector_1.T, Sigma_inv), vector_1)\n",
    "    B = np.dot(np.dot(vector_1.T, Sigma_inv), mu)\n",
    "    C = np.dot(np.dot(mu.T, Sigma_inv), mu)\n",
    "    \n",
    "    # Compute lambda and gamma\n",
    "    denominator = A*C - B**2\n",
    "    lambda_val = (A*m - B) / denominator\n",
    "    gamma = (C - B*m) / denominator\n",
    "    \n",
    "    # Compute w_star\n",
    "    w_star = np.dot(Sigma_inv, (lambda_val * mu + gamma * vector_1))\n",
    "    \n",
    "    return w_star\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the optimize vector $w_1^*$, $w_2^*$ and $w_3^*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_1_star = optimize(Sigma_1, mu, m)\n",
    "w_2_star = optimize(Sigma_2, mu, m)\n",
    "w_3_star = optimize(Sigma_3, mu, m)\n",
    "\n",
    "print(\"w1*\")\n",
    "print(w_1_star)\n",
    "print()\n",
    "print(\"w2*\")\n",
    "print(w_2_star)\n",
    "print()\n",
    "print(\"w3*\")\n",
    "print(w_3_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute portfolio risks $\\sigma_{\\Pi} = \\sqrt{w^{\\top}\\Sigma w}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_1 = np.sqrt(np.dot(np.dot(w_1_star.T,Sigma_1), w_1_star))\n",
    "vol_2 = np.sqrt(np.dot(np.dot(w_2_star.T,Sigma_2), w_2_star))\n",
    "vol_3 = np.sqrt(np.dot(np.dot(w_3_star.T,Sigma_3), w_3_star))\n",
    "\n",
    "print(\"Volatily for portfolio 1 \", vol_1)\n",
    "print(\"Volatily for portfolio 2 \", vol_2)\n",
    "print(\"Volatily for portfolio 3 \", vol_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute loss probability given SR annualy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Probability (Daily): 0.4866830433008509\n",
      "Loss Probability (Monthly): 0.439199996693031\n",
      "Loss Probability (Quarterly): 0.395504730907446\n",
      "Loss Probability (Annual): 0.29805596539487644\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Given annualized Sharpe Ratio\n",
    "SR_annual = 0.53\n",
    "\n",
    "# Calculate daily Sharpe Ratio\n",
    "SR_daily = SR_annual / np.sqrt(252)\n",
    "\n",
    "# Calculate loss probabilities using CDF of standard normal distribution\n",
    "loss_prob_daily = stats.norm.cdf(-SR_daily)\n",
    "loss_prob_monthly = stats.norm.cdf(-SR_annual / np.sqrt(12))\n",
    "loss_prob_quarterly = stats.norm.cdf(-SR_annual / np.sqrt(4))\n",
    "loss_prob_annual = stats.norm.cdf(-SR_annual)\n",
    "\n",
    "# Print the results\n",
    "print(\"Loss Probability (Daily):\", loss_prob_daily)\n",
    "print(\"Loss Probability (Monthly):\", loss_prob_monthly)\n",
    "print(\"Loss Probability (Quarterly):\", loss_prob_quarterly)\n",
    "print(\"Loss Probability (Annual):\", loss_prob_annual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate above 700 random allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Given data\n",
    "returns = mu \n",
    "volatility = np.array([[0.07], [0.28], [0.25], [0.31]])\n",
    "\n",
    "# Number of random portfolios to generate\n",
    "num_portfolios = 700\n",
    "\n",
    "# Initialize arrays to store portfolio statistics\n",
    "portfolio_rets = np.zeros(num_portfolios)\n",
    "portfolio_vols = np.zeros(num_portfolios)\n",
    "sharpe_ratios = np.zeros(num_portfolios)\n",
    "\n",
    "# Generate random portfolio allocations and compute statistics\n",
    "for i in range(num_portfolios):\n",
    "    # Generate random weights\n",
    "    weights = np.random.random(4)\n",
    "    # Normalize to ensure sum of weights is 1\n",
    "    weights /= np.sum(weights)\n",
    "\n",
    "    # Compute portfolio mean and variance\n",
    "    portfolio_ret = np.dot(weights, returns)\n",
    "    portfolio_vol = np.sqrt(np.dot(weights, np.dot(Sigma, weights.T)))\n",
    "\n",
    "    # Calculate Sharpe ratio\n",
    "    sharpe_ratio = portfolio_ret[0] / portfolio_vol\n",
    "\n",
    "    # Store results\n",
    "    portfolio_rets[i] = portfolio_ret[0]\n",
    "    portfolio_vols[i] = portfolio_vol\n",
    "    sharpe_ratios[i] = sharpe_ratio\n",
    "\n",
    "# Create a DataFrame to store portfolio returns, volatilities, and Sharpe ratios\n",
    "portfolio_df = pd.DataFrame({\n",
    "    \"Returns\": portfolio_rets,\n",
    "    \"Volatilities\": portfolio_vols,\n",
    "    \"Sharpe Ratios\": sharpe_ratios\n",
    "})\n",
    "\n",
    "# Results\n",
    "portfolio_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotly express for EF plot\n",
    "import plotly.express as px\n",
    "\n",
    "# Find the index of the portfolio with the maximum Sharpe ratio\n",
    "max_sharpe_index = np.argmax(sharpe_ratios)\n",
    "\n",
    "# Plot the data using Plotly Express\n",
    "fig = px.scatter(portfolio_df, x=\"Volatilities\", y=\"Returns\", color=\"Sharpe Ratios\",\n",
    "                 title=\"Monte Carlo Simulated Portfolio\",\n",
    "                 labels={\"Portfolio Volatilities\": \"Volatility\",\n",
    "                         \"Portfolio Returns\": \"Return\"},\n",
    "                 width=800, height=500).update_traces(mode='markers', marker=dict(symbol='cross'))\n",
    "\n",
    "# Add the portfolio with the maximum Sharpe ratio to the plot with a star symbol\n",
    "fig.add_scatter(\n",
    "        mode='markers',\n",
    "        x=[portfolio_df.iloc[max_sharpe_index]['Volatilities']],\n",
    "        y=[portfolio_df.iloc[max_sharpe_index]['Returns']],\n",
    "        marker=dict(symbol='star', size=10, color='red'),\n",
    "        name='Max Sharpe').update(layout_showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VaR formula\n",
    "\n",
    "$$\n",
    "\\text{VaR}_{10D,t} =  \\text{Factor} \\times \\sigma_{t} \\times \\sqrt{10}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find `Factor` using inverse cdf function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "# Compute `factor`\n",
    "factor = norm.ppf(0.01)\n",
    "factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the nasdaq100 data and calulate returns and VaR given the above equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute returns\n",
    "df = pd.read_csv(\"../exam/nasdaq100.csv\",parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "df['rets'] = np.log(df['Closing Price']).diff()\n",
    "\n",
    "# Compute 10 days VaR \n",
    "window = 21\n",
    "df['VaR_10D'] = factor * df['rets'].rolling(window=window).std() * np.sqrt(10)\n",
    "\n",
    "# Compute 10 days forward returns\n",
    "df['rets_10D'] = np.log(df['Closing Price'].shift(-11) / df['Closing Price'].shift(-1))\n",
    "\n",
    "# Identify breaches\n",
    "df['breach'] = (df['rets_10D'] < df['VaR_10D']).astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The count and percentage of VaR breaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['breach'] == 1\n",
    "pct_var_breaches = df[mask]['breach'].count() / len(df)\n",
    "print('No. of Breaches', df[mask]['breach'].count())\n",
    "print('Pecentage VaR Breaches', pct_var_breaches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The count of consecutive VaR breaches. (1, 1, 1 indicates two consecutive occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the breach column to a list for easier manipulation\n",
    "breach_list = df['breach'].tolist()\n",
    "\n",
    "# Initialize variables\n",
    "consecutive_counts_list = []\n",
    "\n",
    "# Iterate through the list of breach values\n",
    "for i in range(len(breach_list) - 1):\n",
    "    if breach_list[i] == 1 and breach_list[i + 1] == 1:\n",
    "        consecutive_counts_list.append(1)\n",
    "    else:\n",
    "        consecutive_counts_list.append(0)\n",
    "\n",
    "sum (consecutive_counts_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Plot the data with breaches symbol is `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df, x=df.index, y=['VaR_10D', 'rets_10D'], title='NASDAQ100 VaR Back Testing of 99%/10day')\n",
    "fig.add_scatter(x=df[df['breach'] == 1].index, y=df[df['breach'] == 1]['rets_10D'], mode='markers', marker=dict(color='red', symbol='x'), name='Breach')\n",
    "fig.update_layout(xaxis_title='Date', yaxis_title='Values')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the estimation of variance and then calculate the standard deviation $\\sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma_{t+1|t}^{2} = \\lambda \\sigma^{2}_{t|t-1} + (1-\\lambda)r_{t}^{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute returns and squared return\n",
    "df2 = pd.read_csv(\"../exam/nasdaq100.csv\",parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "df2['rets'] = np.log(df2['Closing Price']).diff()\n",
    "df2['sq_rets'] = df2['rets'] **  2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the new VaR using the estimation of EWMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given lambda\n",
    "lambda_given = 0.72\n",
    "\n",
    "# Second day estimation\n",
    "second_day_variance = np.mean(df2['sq_rets'])\n",
    "\n",
    "# Create a list of variance estimation\n",
    "var_est_list = [np.nan, second_day_variance]\n",
    "\n",
    "# Loop through the data starting from the second index and compute the estimation variance then append the result to the list\n",
    "for i in range(1, len(df2)-1):\n",
    "    result = lambda_given * var_est_list[-1] + (1 - lambda_given) * df2.loc[df2.index[i], 'sq_rets']\n",
    "    var_est_list.append(result)\n",
    "\n",
    "# Create a new column in the DataFrame to store variance estimation values\n",
    "df2['vol_est'] = np.sqrt(var_est_list)\n",
    "\n",
    "# Create a new column for 10D Returns and 10D vol estimation\n",
    "df2['VaR_est_10D'] = factor * df2['vol_est'] * np.sqrt(10)\n",
    "df2['rets_10D'] = np.log(df2['Closing Price'].shift(-(11)) / df2['Closing Price'].shift(-1))\n",
    "\n",
    "# Identify breaches\n",
    "df2['breach'] = (df2['rets_10D'] < df2['VaR_est_10D']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Counting breaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df2['breach'] == 1\n",
    "pct_var_breaches = df2[mask]['breach'].count() / len(df2)\n",
    "print('No. of Breaches', df2[mask]['breach'].count())\n",
    "print('Pecentage VaR Breaches', pct_var_breaches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Counting consecutive breaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the breach column to a list for easier manipulation\n",
    "breach_list = df2['breach'].tolist()\n",
    "\n",
    "# Initialize variables\n",
    "consecutive_counts_list = []\n",
    "\n",
    "# Iterate through the list of breach values\n",
    "for i in range(len(breach_list) - 1):\n",
    "    if breach_list[i] == 1 and breach_list[i + 1] == 1:\n",
    "        consecutive_counts_list.append(1)\n",
    "    else:\n",
    "        consecutive_counts_list.append(0)\n",
    "\n",
    "sum (consecutive_counts_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df2, x=df2.index, y=['VaR_est_10D', 'rets_10D'], title='NASDAQ100 VaR Back Testing EWMA')\n",
    "fig.add_scatter(x=df2[df2['breach'] == 1].index, y=df2[df2['breach'] == 1]['rets_10D'], mode='markers', marker=dict(color='red', symbol='x'), name='Breach')\n",
    "fig.update_layout(xaxis_title='Date', yaxis_title='Values')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
